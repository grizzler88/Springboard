{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FantasyNFL_Capstone_Preprocessing (Updated v3).ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNJSpNsoAN/ilcLUB68HCKd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/grizzler88/Springboard/blob/master/Capstone%20-%20Fantasy%20Draft%20Strategy/FantasyNFL_Capstone_Preprocessing_(Updated_v3).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUp_-swjt-v4"
      },
      "source": [
        "# Capstone 1: Fantasy NFL (Pre-processing & Training Data Developmnet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCBp8qMAuSGs"
      },
      "source": [
        "The next step for my Capstone project is to clean up the latest verion of my dataset to ensure it is ready for the Modelling stage of the project."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPqphUbWnh_h"
      },
      "source": [
        "## Getting Started"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnyZlBaZAXJC"
      },
      "source": [
        "### Import packages & load dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ypq-wMAxGSw"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsZghOnjwo2T"
      },
      "source": [
        "df = pd.read_csv('NFL_FantasyData_2015_2019_EDA_v3.csv')\r\n",
        "#df.head()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2k0Dhg1AhS6"
      },
      "source": [
        "### Review Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vp18uLyYytTh"
      },
      "source": [
        "Dataset has unamed column 'Unnamed: 0' from import that is not of value and should be removed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBlhCn-vx7uj"
      },
      "source": [
        "df = df.drop(columns='Unnamed: 0')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq_wACrYyN48"
      },
      "source": [
        "#df.head()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4uJrNQy_ULT",
        "outputId": "41b18f18-1346-44a0-fb9f-8c5240bf9b03"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22410, 47)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNYAKPZU2R77"
      },
      "source": [
        "Next, we will look see what data types are in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6H7QoSlzPFn",
        "outputId": "307368fe-eef1-4191-d736-471f2bfa2416"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 22410 entries, 0 to 22409\n",
            "Data columns (total 47 columns):\n",
            " #   Column           Non-Null Count  Dtype  \n",
            "---  ------           --------------  -----  \n",
            " 0   TEAM             22410 non-null  object \n",
            " 1   OPP              22410 non-null  object \n",
            " 2   DATE             22410 non-null  object \n",
            " 3   SEASON           22410 non-null  int64  \n",
            " 4   WEEK             22410 non-null  object \n",
            " 5   MONTH            22410 non-null  object \n",
            " 6   TIME             22410 non-null  object \n",
            " 7   POS              22410 non-null  object \n",
            " 8   PLAYER           22410 non-null  object \n",
            " 9   FAN_ACTUAL       22410 non-null  float64\n",
            " 10  HOME             22410 non-null  int64  \n",
            " 11  DOME             22410 non-null  int64  \n",
            " 12  GRASS            22410 non-null  int64  \n",
            " 13  SUNDAY           22410 non-null  int64  \n",
            " 14  WEEK_SEASON_ID   22410 non-null  int64  \n",
            " 15  FAN_AVG          22410 non-null  float64\n",
            " 16  PASSCOMP_AVG     22410 non-null  float64\n",
            " 17  PASSATT_AVG      22410 non-null  float64\n",
            " 18  PASSCOMP%_AVG    22410 non-null  float64\n",
            " 19  PASSYDS_AVG      22410 non-null  float64\n",
            " 20  PASSTD_AVG       22410 non-null  float64\n",
            " 21  INT_AVG          22410 non-null  float64\n",
            " 22  QBRAT_AVG        22410 non-null  float64\n",
            " 23  SACK_AVG         22410 non-null  float64\n",
            " 24  SACKYDS_AVG      22410 non-null  float64\n",
            " 25  PASSYDS_300_AVG  22410 non-null  float64\n",
            " 26  PASSYDS_400_AVG  22410 non-null  float64\n",
            " 27  RUSHATT_AVG      22410 non-null  float64\n",
            " 28  RUSHYDS_AVG      22410 non-null  float64\n",
            " 29  RUSHTD_AVG       22410 non-null  float64\n",
            " 30  FUM_AVG          22410 non-null  float64\n",
            " 31  FUMLST_AVG       22410 non-null  float64\n",
            " 32  RUSHYDS_100_AVG  22410 non-null  float64\n",
            " 33  RUSHYDS_200_AVG  22410 non-null  float64\n",
            " 34  TGTS_AVG         22410 non-null  float64\n",
            " 35  REC_AVG          22410 non-null  float64\n",
            " 36  RECYDS_AVG       22410 non-null  float64\n",
            " 37  RECTD_AVG        22410 non-null  float64\n",
            " 38  RECYDS_100_AVG   22410 non-null  float64\n",
            " 39  RECYDS_200_AVG   22410 non-null  float64\n",
            " 40  PTS_FOR_AVG      22410 non-null  float64\n",
            " 41  PTS_AGT_AVG      22410 non-null  float64\n",
            " 42  WIN/TIE_AVG      22410 non-null  float64\n",
            " 43  OPP_PTS_FOR_AVG  22410 non-null  float64\n",
            " 44  OPP_PTS_AGT_AVG  22410 non-null  float64\n",
            " 45  OPP_WIN/TIE_AVG  22410 non-null  float64\n",
            " 46  cluster_4        22410 non-null  int64  \n",
            "dtypes: float64(32), int64(7), object(8)\n",
            "memory usage: 8.0+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mor-LMRc3mvt"
      },
      "source": [
        "There are 8 objects or categorical variables that we will need to make numeric."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT7lDGay3w6w"
      },
      "source": [
        "## Categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYr5lWoN6tcl"
      },
      "source": [
        "object_cols = list(df.columns[df.dtypes == np.object])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtHoTad68Col",
        "outputId": "a133aaf7-6483-4fd5-bb18-8ff480ed8cfb"
      },
      "source": [
        "for x in object_cols:\r\n",
        "  val = df[x].nunique()\r\n",
        "  print(x,' = ', val)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEAM  =  32\n",
            "OPP  =  32\n",
            "DATE  =  248\n",
            "WEEK  =  17\n",
            "MONTH  =  5\n",
            "TIME  =  3\n",
            "POS  =  4\n",
            "PLAYER  =  1012\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnJQypM48uY9"
      },
      "source": [
        "The review of the ojbect columns shows that including them all would create +1,300 new columns.\r\n",
        "\r\n",
        "For the moment, we will not look at the date fields of DATE, WEEK, MONTH, DAY, TIME.\r\n",
        "\r\n",
        "We will instead concentrate on the POS, TEAM, OPP, and PLAYER columns. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVIDYK5FyVI3"
      },
      "source": [
        "### Remove 'PLAYER' column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkVkZkoVe4GD"
      },
      "source": [
        "First, I will remove the PLAYER field. Turning this to dummy values would create 1,011 additional columns which would add too many dimensions to the problem. It is also unlikely that the player's name itself will be a main indicator of performance, but rather the statistics that they produce."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWD5sveDfaOL"
      },
      "source": [
        "df = df.drop(columns='PLAYER')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX93LRwKyk3v"
      },
      "source": [
        "#df.shape"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZv53pN8yrkz"
      },
      "source": [
        "### Remove 'TEAM' and 'OPP' column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh_J3pwjfk2E"
      },
      "source": [
        "Transforming the TEAM and OPP columns into dummy variables would add 31 columns each. We also noted during our EDA that, althought the Team and Coach columns were providing us with information, that this information could be proxied using team peformance statisitcs (i.e. it likely isn't the name of the team that influences a player performance but rather the team performance under a certain organisation structure that influences it).\r\n",
        "\r\n",
        "With this in mind, I have decided to remove both the 'TEAM' and 'OPP' column. However, based on the performance of our initial modelling we could look to reintroduce if required."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzHICw-R0NHO"
      },
      "source": [
        "df = df.drop(columns=['TEAM', 'OPP'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brDbdPj80TtW"
      },
      "source": [
        "#df.shape"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNoOn21-0ZBP"
      },
      "source": [
        "### Create dummy variables for 'POS' column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xJT7yb80eiw"
      },
      "source": [
        "Throughout the EDA, we saw that position of a player was an important indicator of fantasy performance and therefore we will include it in our model. To do this, we will create dummy variables below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILAv0Klb-Pga"
      },
      "source": [
        "dummy_POS = pd.get_dummies(df.POS, prefix='POS', drop_first=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwzwF0hM_Wrs"
      },
      "source": [
        "df = pd.concat([df, dummy_POS], axis=1).drop(columns=['POS'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeXkuZv4Dj0N",
        "outputId": "6acc7360-a3de-4673-e813-c991d76cb8fa"
      },
      "source": [
        "df.head()\r\n",
        "df.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22410, 46)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nu4suFeODoNi"
      },
      "source": [
        "## Date variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0posDJxm4UUA"
      },
      "source": [
        "### Date"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJvC-z624Xsa"
      },
      "source": [
        "Our data has 248 unique values in our 'DATE' column. While we want to capture some time element in our model, I don't believe it needs to be as granular as a specific date. For this reason, we will remove the date field from our data set for now but can look to include again if we believe the time is becoming an issue with our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Sp-s5vQ5Yn9"
      },
      "source": [
        "df = df.drop(columns=['DATE'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LieMCfR55fgo",
        "outputId": "bbaf25e4-2db0-43c8-e08c-df3799089fcf"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22410, 45)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBIT6wzk4Prw"
      },
      "source": [
        "### Week, Month & Season"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-C8_D2Oc5khj"
      },
      "source": [
        "As mentioned when removing the 'DATE' column, we have other variables in our dataset that we believe can capture the time and date aspect of data. This namely relates to the following columns:\r\n",
        "\r\n",
        "* 'WEEK' - what gamewek was a game played in (there are 17 gameweeks in an NFL season)\r\n",
        "* 'MONTH' - what month was a game played in\r\n",
        "* 'SEASON' - what season was a game played in\r\n",
        "* 'WEEK_SEASON_ID' - what number in order did a game get played in since start of this dataset\r\n",
        "* 'SUNDAY' - was game played on a Sunday (1 if yes, 0 if no)\r\n",
        "* 'TIME' - what time was game played (Noon, Afternoon, Night)\r\n",
        "\r\n",
        "\r\n",
        "For this, there are two main decisions that need to be answered in order:\r\n",
        "\r\n",
        "1.  Do we want to include 'WEEK_SEASON_ID'?\r\n",
        "  * This is an ordered numeric series that may cause issues with our model if not correctly applied. For this reason, it is probably best to __remove 'WEEK_SEASON_ID'.__\r\n",
        "\r\n",
        "2.  Do we want to keep 'WEEK' or 'MONTH' column?\r\n",
        "  * During our EDA, we found that both showed a trend that as the season went on the lower average fantasy points became. However, including both will likely create a duplication of information so it is probably best to proceed with only one for our modelling. __As 'MONTH' required fewer variables, we will begin with this but can return to include 'WEEK' if required later.__\r\n",
        "\r\n",
        "\r\n",
        "This means that we will proceed with the 'MONTH', 'SEASON', 'TIME', and 'SUNDAY' columns to capture the time elements of the data in our modelling. To do this, we will need to create dummy variable for all the columns (for 'SEASON' we will first have to turn into an object), except for 'SUNDAY' which is already created as a boolean/binary column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJyT7zT69LnK"
      },
      "source": [
        "df = df.drop(columns=['WEEK_SEASON_ID', 'WEEK'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZyFRbCH-mHn",
        "outputId": "408ba47e-d366-47e6-e7a3-2d96ac6fb8c1"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22410, 43)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H9wJLPe9T4v"
      },
      "source": [
        "df['SEASON'] = df['SEASON'].astype(object)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wwqjILg-wHz"
      },
      "source": [
        "dummy_SEASON = pd.get_dummies(df.SEASON, prefix='SEASON', drop_first=True)\r\n",
        "dummy_MONTH = pd.get_dummies(df.MONTH, prefix='MONTH', drop_first=True)\r\n",
        "dummy_TIME = pd.get_dummies(df.TIME, prefix='TIME', drop_first=True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3mtzuvd-8rr"
      },
      "source": [
        "df = pd.concat([df, dummy_SEASON, dummy_MONTH, dummy_TIME], axis=1).drop(columns=['SEASON', 'MONTH', 'TIME'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4K67_Y3d_KzR",
        "outputId": "995421bc-7be4-4f22-9f3e-a462bdc4f05e"
      },
      "source": [
        "df.head()\r\n",
        "df.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(22410, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcCzcHqg8JWd"
      },
      "source": [
        "## Training and Test Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OUsF85f8Wv0"
      },
      "source": [
        "Now that all the data is in numeric format, we will have to scale to ensure it has the correct distribution to support modelling. However, prior to this, we will need to split our data into Train and Test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQHA5ZJa_ln3"
      },
      "source": [
        "First, I will import the train_test_split fuction from sklearn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0kntCA98Vy6"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxGzh1Wx_v0x"
      },
      "source": [
        "Next, I will breakout my data into independent and dependent variables. \r\n",
        "\r\n",
        "For our model, we have two potential dependent variables  - 'FAN_ACTUAL' or 'cluster_4'.  'FAN_ACTUAL' is a a continuous variable and 'cluster_4' is a categorical variable meaning the choice between which variable we use will dicate what type of model - regression or classification.\r\n",
        "\r\n",
        "To start we will focus on 'FAN_ACTUAL'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkgtmNEe-aWb"
      },
      "source": [
        "X = df.drop(['FAN_ACTUAL', 'cluster_4'], axis=1)\r\n",
        "y = df['FAN_ACTUAL']"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOQOTokG_-bx"
      },
      "source": [
        "Now, I will split my data into training and test data. Due to the high number of dimensions in the dataset, I am going to set my test zize at 20% - lower than the default option of 25%. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MlVnSQ690GA"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Uh0X6PNBefn"
      },
      "source": [
        "## Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "saGtf5BVTAwv",
        "outputId": "8362a1fa-0297-4664-9fb1-c6bd2c8086b5"
      },
      "source": [
        "X.describe()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>HOME</th>\n",
              "      <th>DOME</th>\n",
              "      <th>GRASS</th>\n",
              "      <th>SUNDAY</th>\n",
              "      <th>FAN_AVG</th>\n",
              "      <th>PASSCOMP_AVG</th>\n",
              "      <th>PASSATT_AVG</th>\n",
              "      <th>PASSCOMP%_AVG</th>\n",
              "      <th>PASSYDS_AVG</th>\n",
              "      <th>PASSTD_AVG</th>\n",
              "      <th>INT_AVG</th>\n",
              "      <th>QBRAT_AVG</th>\n",
              "      <th>SACK_AVG</th>\n",
              "      <th>SACKYDS_AVG</th>\n",
              "      <th>PASSYDS_300_AVG</th>\n",
              "      <th>PASSYDS_400_AVG</th>\n",
              "      <th>RUSHATT_AVG</th>\n",
              "      <th>RUSHYDS_AVG</th>\n",
              "      <th>RUSHTD_AVG</th>\n",
              "      <th>FUM_AVG</th>\n",
              "      <th>FUMLST_AVG</th>\n",
              "      <th>RUSHYDS_100_AVG</th>\n",
              "      <th>RUSHYDS_200_AVG</th>\n",
              "      <th>TGTS_AVG</th>\n",
              "      <th>REC_AVG</th>\n",
              "      <th>RECYDS_AVG</th>\n",
              "      <th>RECTD_AVG</th>\n",
              "      <th>RECYDS_100_AVG</th>\n",
              "      <th>RECYDS_200_AVG</th>\n",
              "      <th>PTS_FOR_AVG</th>\n",
              "      <th>PTS_AGT_AVG</th>\n",
              "      <th>WIN/TIE_AVG</th>\n",
              "      <th>OPP_PTS_FOR_AVG</th>\n",
              "      <th>OPP_PTS_AGT_AVG</th>\n",
              "      <th>OPP_WIN/TIE_AVG</th>\n",
              "      <th>POS_RB</th>\n",
              "      <th>POS_TE</th>\n",
              "      <th>POS_WR</th>\n",
              "      <th>SEASON_2016</th>\n",
              "      <th>SEASON_2017</th>\n",
              "      <th>SEASON_2018</th>\n",
              "      <th>SEASON_2019</th>\n",
              "      <th>MONTH_January</th>\n",
              "      <th>MONTH_November</th>\n",
              "      <th>MONTH_October</th>\n",
              "      <th>MONTH_September</th>\n",
              "      <th>TIME_Night</th>\n",
              "      <th>TIME_Noon</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>22410.00000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.00000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "      <td>22410.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.49286</td>\n",
              "      <td>0.250870</td>\n",
              "      <td>0.559036</td>\n",
              "      <td>0.847256</td>\n",
              "      <td>7.540876</td>\n",
              "      <td>2.452454</td>\n",
              "      <td>3.861323</td>\n",
              "      <td>0.079474</td>\n",
              "      <td>27.963528</td>\n",
              "      <td>0.175565</td>\n",
              "      <td>0.089573</td>\n",
              "      <td>11.367761</td>\n",
              "      <td>0.256783</td>\n",
              "      <td>1.699108</td>\n",
              "      <td>0.053429</td>\n",
              "      <td>0.003153</td>\n",
              "      <td>2.895828</td>\n",
              "      <td>12.283151</td>\n",
              "      <td>0.089194</td>\n",
              "      <td>0.116354</td>\n",
              "      <td>0.055332</td>\n",
              "      <td>0.042600</td>\n",
              "      <td>0.000491</td>\n",
              "      <td>3.633118</td>\n",
              "      <td>2.441280</td>\n",
              "      <td>27.912379</td>\n",
              "      <td>0.174554</td>\n",
              "      <td>0.084627</td>\n",
              "      <td>0.000807</td>\n",
              "      <td>22.746088</td>\n",
              "      <td>22.665462</td>\n",
              "      <td>0.504332</td>\n",
              "      <td>22.667321</td>\n",
              "      <td>22.712480</td>\n",
              "      <td>0.500892</td>\n",
              "      <td>0.296029</td>\n",
              "      <td>0.184516</td>\n",
              "      <td>0.391031</td>\n",
              "      <td>0.203614</td>\n",
              "      <td>0.204596</td>\n",
              "      <td>0.202811</td>\n",
              "      <td>0.201830</td>\n",
              "      <td>0.025524</td>\n",
              "      <td>0.23784</td>\n",
              "      <td>0.253503</td>\n",
              "      <td>0.191120</td>\n",
              "      <td>0.196430</td>\n",
              "      <td>0.549353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.49996</td>\n",
              "      <td>0.433524</td>\n",
              "      <td>0.496514</td>\n",
              "      <td>0.359749</td>\n",
              "      <td>6.161600</td>\n",
              "      <td>6.878654</td>\n",
              "      <td>10.756930</td>\n",
              "      <td>0.208177</td>\n",
              "      <td>78.749941</td>\n",
              "      <td>0.535357</td>\n",
              "      <td>0.296911</td>\n",
              "      <td>29.988032</td>\n",
              "      <td>0.778899</td>\n",
              "      <td>5.273701</td>\n",
              "      <td>0.222486</td>\n",
              "      <td>0.030521</td>\n",
              "      <td>4.947567</td>\n",
              "      <td>22.129624</td>\n",
              "      <td>0.219471</td>\n",
              "      <td>0.239117</td>\n",
              "      <td>0.138890</td>\n",
              "      <td>0.184523</td>\n",
              "      <td>0.011799</td>\n",
              "      <td>2.909681</td>\n",
              "      <td>1.906358</td>\n",
              "      <td>25.561921</td>\n",
              "      <td>0.262745</td>\n",
              "      <td>0.248650</td>\n",
              "      <td>0.014224</td>\n",
              "      <td>5.930808</td>\n",
              "      <td>5.475222</td>\n",
              "      <td>0.285957</td>\n",
              "      <td>5.940760</td>\n",
              "      <td>5.459414</td>\n",
              "      <td>0.286925</td>\n",
              "      <td>0.456514</td>\n",
              "      <td>0.387913</td>\n",
              "      <td>0.487992</td>\n",
              "      <td>0.402694</td>\n",
              "      <td>0.403415</td>\n",
              "      <td>0.402102</td>\n",
              "      <td>0.401375</td>\n",
              "      <td>0.157715</td>\n",
              "      <td>0.42577</td>\n",
              "      <td>0.435026</td>\n",
              "      <td>0.393192</td>\n",
              "      <td>0.397306</td>\n",
              "      <td>0.497569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-2.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-6.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.250000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>18.750000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>18.500000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.841667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.250000</td>\n",
              "      <td>2.250000</td>\n",
              "      <td>21.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>22.500000</td>\n",
              "      <td>22.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>22.250000</td>\n",
              "      <td>22.500000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>14.729167</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.500000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>26.500000</td>\n",
              "      <td>26.250000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>26.500000</td>\n",
              "      <td>26.500000</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>44.090000</td>\n",
              "      <td>36.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>403.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>158.300000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>29.500000</td>\n",
              "      <td>168.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>43.750000</td>\n",
              "      <td>43.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>43.750000</td>\n",
              "      <td>43.750000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              HOME          DOME  ...    TIME_Night     TIME_Noon\n",
              "count  22410.00000  22410.000000  ...  22410.000000  22410.000000\n",
              "mean       0.49286      0.250870  ...      0.196430      0.549353\n",
              "std        0.49996      0.433524  ...      0.397306      0.497569\n",
              "min        0.00000      0.000000  ...      0.000000      0.000000\n",
              "25%        0.00000      0.000000  ...      0.000000      0.000000\n",
              "50%        0.00000      0.000000  ...      0.000000      1.000000\n",
              "75%        1.00000      1.000000  ...      0.000000      1.000000\n",
              "max        1.00000      1.000000  ...      1.000000      1.000000\n",
              "\n",
              "[8 rows x 48 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSg4twWmRDZK"
      },
      "source": [
        "As can be seen in the table above, the ranges of values differs greatly between each column. This suggest that in order to compare values across columns, we should to transform all are values to a similar scale.\r\n",
        "\r\n",
        "To do this, we will use the StandarScaler() method from sklearn.preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3WDmAoVGbz-"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQKDT8GJGlVw"
      },
      "source": [
        "scaler = StandardScaler()\r\n",
        "scaler.fit(X_train)\r\n",
        "X_train_scaled = scaler.transform(X_train)\r\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ_4KcCVICHY"
      },
      "source": [
        "#pd.DataFrame(X_train_scaled, columns=list(X.columns))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGol3qI4ImZM"
      },
      "source": [
        "#pd.DataFrame(X_test_scaled, columns=list(X.columns))"
      ],
      "execution_count": 31,
      "outputs": []
    }
  ]
}